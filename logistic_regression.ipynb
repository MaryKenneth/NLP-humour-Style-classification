{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maryk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maryk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\maryk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from split_data_utils import train_test_spliting\n",
    "from data_preprocessing import lemmatize_text_with_pos, tokens\n",
    "from ngram_utils import generate_ngrams, build_ngram_vocab, bag_of_ngrams\n",
    "from tf_idf_embedding_utils import tf_idf, tokenise, build_vocabulary, log_count_terms, count_terms\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download the punkt tokenizer data\n",
    "nltk.download('wordnet')  # Download the WordNet data\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Humour_style.xlsx\")   # Read Excel dataset \n",
    "df = df[['JOKES', 'LABELS']]              # Extract Only the Jokes and Labels Column\n",
    "df = df[:1263]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dataset Into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train object\n",
      "y_train (1010,)\n",
      "x_test object\n",
      "y_test (253,)\n",
      "['4 ways to become a better risk taker'\n",
      " '“Never argue with stupid people, they will drag you down to their level and then beat you with experience.”'\n",
      " '“Worrying is like paying a debt you don’t owe.”' ...\n",
      " \"Worker dies at minnesota vikings' stadium construction site\"\n",
      " \"sharps' injuries could pose hiv, hepatitis risk to surgeons\"\n",
      " \"My set is full of them, but I have a go to bit about how awful it is being a fat chick with small tits that almost always saves me when I'm faltering.\"]\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "seed = 100\n",
    "x_train, x_test, y_train, y_test = train_test_spliting(df,train_ratio,seed)\n",
    "\n",
    "print(\"x_train\",x_train.dtype)   # Get the shape of the training features (Number of instance, number of features/column)\n",
    "print(\"y_train\",y_train.shape)   # Get the shape of the training label (Number of instance, number of column)\n",
    "print(\"x_test\",x_test.dtype)\n",
    "print(\"y_test\",y_test.shape)\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize each example in the train dataset\n",
    "lemmatized_x_train  = [lemmatize_text_with_pos(example) for example in x_train]\n",
    "\n",
    "# Lemmatize each example in the test dataset\n",
    "lemmatized_x_test  = [lemmatize_text_with_pos(example) for example in x_test]\n",
    "\n",
    "x_train = np.array(lemmatized_x_train )   # Convert Train data to Numpy Array \n",
    "x_test = np.array(lemmatized_x_test)      # Convert Test data to Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Text Classification\n",
    "In this notebook, we explore different feature engineering techniques for text classification using a Logistic Regression model. The implemented features include Bag-of-Ngrams, TF-IDF, and Positive/Negative word counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-Ngrams Features\n",
    "\n",
    "The Bag-of-Ngrams representation captures the frequency of word combinations (N-grams) in a document. The following steps outline the process:\n",
    "\n",
    "1. **Generate N-grams**: Convert the input text into a list of N-grams.\n",
    "2. **Build Vocabulary**: Create a set of unique N-grams to form the vocabulary.\n",
    "3. **Create Bag-of-Ngrams**: Count the occurrences of each N-gram in the text and represent the document as a dense array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 11794\n",
      "Train Features Shape: (1010, 11794)\n",
      "Test Features Shape: (253, 11794)\n"
     ]
    }
   ],
   "source": [
    "### Get vocabulary size from train dataset\n",
    "train_vocab  = set()\n",
    "\n",
    "# Build the vocabulary from train N-grams\n",
    "for example in x_train:\n",
    "    vocabs = generate_ngrams(example,2)\n",
    "    train_vocab.update(vocabs)\n",
    "\n",
    "print(f\"Vocabulary Size: {len(train_vocab)}\")\n",
    "\n",
    "# Convert train N-grams to vectors using the vocabulary\n",
    "def convert_to_vectors(data, vocab):\n",
    "    features = []\n",
    "    for example in data:\n",
    "        vectors = bag_of_ngrams(example, 2, vocab)\n",
    "        features.append(vectors)\n",
    "    return np.squeeze(np.array(features))\n",
    "\n",
    "# Convert train N-grams to vectors\n",
    "x_train_features = convert_to_vectors(x_train, train_vocab)\n",
    "\n",
    "# Convert test N-grams to vectors using the same vocabulary\n",
    "x_test_features = convert_to_vectors(x_test, train_vocab)\n",
    "\n",
    "print(f\"Train Features Shape: {x_train_features.shape}\")\n",
    "print(f\"Test Features Shape: {x_test_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF (Term Frequency-Inverse Document Frequency) Features\n",
    "TF-IDF is a numerical statistic that reflects the importance of a word in a document relative to a collection of documents. The steps are as follows:\n",
    "\n",
    "1. **Tokenization:** Break the text into individual words (tokens).\n",
    "2. **Compute TF-IDF:** Use the tf-idf method calculate TF-IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  4009\n",
      "------------------------------ \n",
      "Train matrix  (1010, 4009)\n",
      "------------------------------ \n",
      "Test matrix  (253, 4009)\n"
     ]
    }
   ],
   "source": [
    "# Converting to Train data to lowercases\n",
    "train_lower = [sentence.lower() for sentence in x_train]\n",
    "\n",
    "vocabulary  = build_vocabulary(train_lower)\n",
    "print(\"Vocabulary: \", len(vocabulary))\n",
    "\n",
    "# TF-IDF vectors for Train dataset\n",
    "tf_idf_values = tf_idf(train_lower,vocabulary)\n",
    "tf_idf_matrix = []                      #Final Train dataset of tf-idf embeddings\n",
    "for sentence in train_lower:\n",
    "    tf_idf_sentence = []                #Store tf-idf for each sentence\n",
    "    for word in tokenise(sentence):\n",
    "        tf_idf_sentence .append(tf_idf_values[word])\n",
    "\n",
    "    # Pad exach sentences to fixed length of vocabulary size\n",
    "    padded_tf_idf_sentence=  np.pad(np.array(tf_idf_sentence), (0, len(vocabulary) - len(tf_idf_sentence))) \n",
    "    tf_idf_matrix.append(padded_tf_idf_sentence)\n",
    "\n",
    "tf_idf_matrix = np.array(tf_idf_matrix)\n",
    "print(\"-\" *30,\"\\nTrain matrix \", np.array(tf_idf_matrix).shape)\n",
    "\n",
    "# Converting to Test Dataset to lowercases\n",
    "test_lower = [sentence.lower() for sentence in x_test]\n",
    "\n",
    "# TF-IDF vectors for Text dataset\n",
    "X_text_tf_idf_matrix = []\n",
    "for sentence in test_lower:\n",
    "    tf_idf_sentence = []\n",
    "    for word in tokenise(sentence):\n",
    "        # Use get method to handle the case where the word is not in the dictionary\n",
    "        tf_idf_sentence.append(tf_idf_values.get(word, 0.0))\n",
    "    padded_tf_idf_sentence=  np.pad(np.array(tf_idf_sentence), (0, len(vocabulary) - len(tf_idf_sentence))) \n",
    "    X_text_tf_idf_matrix.append(padded_tf_idf_sentence)\n",
    "\n",
    "X_text_tf_idf_matrix =np.array(X_text_tf_idf_matrix)\n",
    "print(\"-\" *30,\"\\nTest matrix \", np.array(X_text_tf_idf_matrix).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positive/Negative and Pronoun Word Counts\n",
    "This feature engineering approach counts the number of positive and negative words in a text. It involves the following steps:\n",
    "\n",
    "1. **Tokenization:** Tokenize the text into words.\n",
    "2. **Count Positive/Negative Words:** Use predefined lists of positive, negative and pronoun words to count occurrences.\n",
    "\n",
    "Note: Can add more word counts based on different criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010, 4)\n",
      "(253, 4)\n"
     ]
    }
   ],
   "source": [
    "# Read positive and negative lexicons\n",
    "positive_lexicon  = np.array(pd.read_fwf(\"positive-words.txt\"))\n",
    "negative_lexicon  = np.array(pd.read_fwf(\"negative-words.txt\"))\n",
    "\n",
    "def features(x):\n",
    "    # Tokenize the text\n",
    "    first_pro = [\"i\",\"we\",\"us\",\"me\",\"myself\",'my','mine',\"our\",\"ours\",\"ourselves\"]\n",
    "    \n",
    "    sec_pro = [\"you\",\"your\",\"yours\",\"him\",\"her\",'he','their',\"them\",\"they\",\n",
    "               \"it\",\"its\",\"theirs\",\"his\",\"she\",\"hers\",\"himself\", \n",
    "               \"herself\", \"itself\", \"themselves\"]\n",
    "    \n",
    "    words = word_tokenize(x.lower())\n",
    "\n",
    "    # Count number of positive and negative words in a sentence \n",
    "    pos_count = sum(word in positive_lexicon for word in words) \n",
    "    neg_count = sum(word in negative_lexicon for word in words) \n",
    "\n",
    "    # Count occurrences of first person and second person pronouns\n",
    "    f_p_count = sum(word in first_pro for word in words) \n",
    "    s_p_count = sum(word in sec_pro for word in words)\n",
    "\n",
    "    return pos_count, neg_count, f_p_count, s_p_count\n",
    "\n",
    "# Extract features for each example in the train dataset\n",
    "x_train_feature_pnp = np.array([features(example) for example in x_train])\n",
    "\n",
    "# Extract features for each example in the test dataset\n",
    "x_test_feature_pnp = np.array([features(example) for example in x_test])\n",
    "\n",
    "# Print the shapes of the feature matrices\n",
    "print(x_train_feature_pnp.shape)\n",
    "print(x_test_feature_pnp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logistic Regression Model\n",
    "\n",
    "The Multinomial Logistic Regression model is used for the Humour style multi-class classification problems. It extends the binary logistic regression to handle multiple classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    # Z-score standardization\n",
    "    return (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    # Sigmoid activation function\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    # Softmax activation function for multi-class classification\n",
    "    exp_z = np.exp(z - np.max(z))  # Subtracting the max for numerical stability to prevent numerical overflow.\n",
    "    return exp_z / exp_z.sum(axis=0, keepdims=True)\n",
    "\n",
    "def oneHot(y):\n",
    "    # Convert class labels to one-hot encoded vectors\n",
    "    onehot_y = np.zeros((len(y),len(np.unique(y))), dtype=int)\n",
    "    onehot_y[np.arange(len(y)),y] = 1 #np.arrange is used to create indices\n",
    "    onehot_y = onehot_y.T\n",
    "    return onehot_y\n",
    "\n",
    "class MultiClass_LogisticReg:\n",
    "    def __init__(self, n_input, n_output, learning_rate=0.1, n_epoch=1000):\n",
    "        # Initialize logistic regression model parameters\n",
    "        self.n_input  = n_input\n",
    "        self.n_output = n_output\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epoch = n_epoch\n",
    "        self.w = np.random.rand(n_output,n_input) - 0.5 # range form -0.5 to 0.5\n",
    "        self.b = np.random.rand(n_output,1) - 0.5\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the model\n",
    "        return softmax(np.dot(self.w, x.T) + self.b)\n",
    "    \n",
    "    def loss(self, x,y):\n",
    "        # Compute categorical cross-entropy loss\n",
    "        predictions = self.forward(x)\n",
    "        target = oneHot(y)\n",
    "        epsilon = 1e-15  # Small constant to avoid log(0)\n",
    "        predictions = np.clip(predictions, epsilon, 1 - epsilon)  # Clip predictions to avoid log(0)\n",
    "        loss = -np.sum(target * np.log(predictions))\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, y):\n",
    "        # Compute gradients for weight and bias\n",
    "        y = oneHot(y)\n",
    "        d_w = np.dot(self.forward(x) - y,x)/y.size\n",
    "        d_b = np.sum(self.forward(x) - y, axis=1,  keepdims=True)/y.size\n",
    "        return d_w, d_b\n",
    "    \n",
    "    def update_params(self, x, y):\n",
    "         d_w, d_b = self.gradient(x,y)\n",
    "         self.w = self.w - self.learning_rate * d_w\n",
    "         self.b = self.b - self.learning_rate * d_b\n",
    "         return self.w, self.b\n",
    "    \n",
    "    def get_prediction(self, pred):\n",
    "        # Get class predictions based on the highest probability\n",
    "         return np.argmax(pred, axis=0)\n",
    "    \n",
    "    def get_accuracy(self,predictions, y):\n",
    "        # Calculate classification accuracy\n",
    "        assert len(predictions) == len(y)\n",
    "        try:\n",
    "            print(f'Pred: {predictions} \\t truth: {y}')\n",
    "            return np.sum(predictions == y) /len(y)\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "\n",
    "    def learning_rate_schedule(self, epoch):\n",
    "        # Implement a learning rate schedule if needed\n",
    "        return self.learning_rate / (1 + epoch / self.n_epoch)  \n",
    "\n",
    "    def fit(self,x,y, x_val=None, y_val=None, patience=100):\n",
    "        best_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(self.n_epoch):\n",
    "            #forward pass\n",
    "            prediction = self.forward(x)\n",
    "\n",
    "            # Calculate and print loss\n",
    "            loss = self.loss(x,y)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch: {epoch} \\t Loss: {loss}')\n",
    "\n",
    "                # Early stopping check\n",
    "                if x_val is not None and y_val is not None:\n",
    "                    val_loss = self.loss(x_val, y_val)\n",
    "                    print(f'Validation Loss: {val_loss}')\n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        best_epoch = epoch\n",
    "                    elif epoch - best_epoch > patience:\n",
    "                        print(f'Early stopping at epoch {epoch}. Best validation loss: {best_loss}')\n",
    "                        break\n",
    "\n",
    "            # Update parameters (weights and biases)\n",
    "            self.update_params(x, y)\n",
    "\n",
    "            # Optionally, print accuracy\n",
    "            if epoch % 100 == 0:\n",
    "                pred = self.get_prediction(prediction)\n",
    "                accuracy = self.get_accuracy(pred, y)\n",
    "                print(\"Accuracy: \", accuracy)\n",
    "\n",
    "        # Save the best model parameters\n",
    "        if x_val is not None and y_val is not None:\n",
    "            print(\"Saving best model parameters.\")\n",
    "            self.save_model()\n",
    "\n",
    "    def save_model(self):\n",
    "        # Save your model parameters to a file or any other storage\n",
    "        np.savez('tf_idf_LR.npz', w=self.w, b=self.b)\n",
    "        print(\"Model saved.\")\n",
    "\n",
    "    def load_model(self, filename='tf_idf_LR.npz'):\n",
    "        # Load model parameters from a file\n",
    "        loaded_params = np.load(filename)\n",
    "        self.w = loaded_params['w']\n",
    "        self.b = loaded_params['b']\n",
    "        print(\"Model loaded.\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Use the loaded model parameters for prediction\n",
    "        prediction = self.forward(x)\n",
    "        pred_labels = self.get_prediction(prediction)\n",
    "        return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Loss: 1678.8931923533062\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.12673267326732673\n",
      "Epoch: 100 \t Loss: 1655.509457725071\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.12871287128712872\n",
      "Epoch: 200 \t Loss: 1638.5748282862378\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.1594059405940594\n",
      "Epoch: 300 \t Loss: 1624.5050283489406\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.17524752475247524\n",
      "Epoch: 400 \t Loss: 1611.8956875790022\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.20693069306930692\n",
      "Epoch: 500 \t Loss: 1600.1820962061825\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.24554455445544554\n",
      "Epoch: 600 \t Loss: 1589.1297594921873\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.27920792079207923\n",
      "Epoch: 700 \t Loss: 1578.6333324243933\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3079207920792079\n",
      "Epoch: 800 \t Loss: 1568.6376156381957\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3287128712871287\n",
      "Epoch: 900 \t Loss: 1559.1069627772713\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3306930693069307\n",
      "Epoch: 1000 \t Loss: 1550.013608445813\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3405940594059406\n",
      "Epoch: 1100 \t Loss: 1541.3332770338109\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.35247524752475246\n",
      "Epoch: 1200 \t Loss: 1533.0435562070002\n",
      "Pred: [4 0 0 ... 0 4 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3613861386138614\n",
      "Epoch: 1300 \t Loss: 1525.1233064622813\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.36534653465346534\n",
      "Epoch: 1400 \t Loss: 1517.5524518118814\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3683168316831683\n",
      "Epoch: 1500 \t Loss: 1510.3119056555272\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.37326732673267327\n",
      "Epoch: 1600 \t Loss: 1503.3835405647287\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.37425742574257426\n",
      "Epoch: 1700 \t Loss: 1496.7501688773546\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3801980198019802\n",
      "Epoch: 1800 \t Loss: 1490.3955227564418\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.38811881188118813\n",
      "Epoch: 1900 \t Loss: 1484.3042304205524\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3891089108910891\n",
      "Epoch: 2000 \t Loss: 1478.4617881620698\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.3930693069306931\n",
      "Epoch: 2100 \t Loss: 1472.8545287524692\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.39603960396039606\n",
      "Epoch: 2200 \t Loss: 1467.4695870989533\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.39702970297029705\n",
      "Epoch: 2300 \t Loss: 1462.2948640195668\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4069306930693069\n",
      "Epoch: 2400 \t Loss: 1457.3189889155103\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4089108910891089\n",
      "Epoch: 2500 \t Loss: 1452.5312820049003\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4089108910891089\n",
      "Epoch: 2600 \t Loss: 1447.9217166665671\n",
      "Pred: [4 0 0 ... 0 0 4] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.41287128712871285\n",
      "Epoch: 2700 \t Loss: 1443.4808823350913\n",
      "Pred: [4 0 0 ... 0 0 3] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.41386138613861384\n",
      "Epoch: 2800 \t Loss: 1439.1999482925628\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4158415841584158\n",
      "Epoch: 2900 \t Loss: 1435.0706286193595\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4168316831683168\n",
      "Epoch: 3000 \t Loss: 1431.085148495305\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4188118811881188\n",
      "Epoch: 3100 \t Loss: 1427.2362119830825\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.42277227722772276\n",
      "Epoch: 3200 \t Loss: 1423.51697137667\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.42574257425742573\n",
      "Epoch: 3300 \t Loss: 1419.920998157663\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4267326732673267\n",
      "Epoch: 3400 \t Loss: 1416.4422555704568\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4277227722772277\n",
      "Epoch: 3500 \t Loss: 1413.0750728022504\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4287128712871287\n",
      "Epoch: 3600 \t Loss: 1409.8141207346546\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4287128712871287\n",
      "Epoch: 3700 \t Loss: 1406.6543892193347\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4306930693069307\n",
      "Epoch: 3800 \t Loss: 1403.5911658198156\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4316831683168317\n",
      "Epoch: 3900 \t Loss: 1400.6200159545\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4316831683168317\n",
      "Epoch: 4000 \t Loss: 1397.7367643715365\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43267326732673267\n",
      "Epoch: 4100 \t Loss: 1394.9374778838192\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4316831683168317\n",
      "Epoch: 4200 \t Loss: 1392.2184492917067\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4287128712871287\n",
      "Epoch: 4300 \t Loss: 1389.57618242159\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4297029702970297\n",
      "Epoch: 4400 \t Loss: 1387.0073782099375\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43366336633663366\n",
      "Epoch: 4500 \t Loss: 1384.5089217646437\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43564356435643564\n",
      "Epoch: 4600 \t Loss: 1382.0778703381852\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43465346534653465\n",
      "Epoch: 4700 \t Loss: 1379.7114421501142\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43465346534653465\n",
      "Epoch: 4800 \t Loss: 1377.407005999617\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43465346534653465\n",
      "Epoch: 4900 \t Loss: 1375.1620716121977\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43564356435643564\n",
      "Epoch: 5000 \t Loss: 1372.9742806678798\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.43663366336633663\n",
      "Epoch: 5100 \t Loss: 1370.8413984616132\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4376237623762376\n",
      "Epoch: 5200 \t Loss: 1368.7613061498128\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4405940594059406\n",
      "Epoch: 5300 \t Loss: 1366.7319935400617\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4405940594059406\n",
      "Epoch: 5400 \t Loss: 1364.7515523839963\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4415841584158416\n",
      "Epoch: 5500 \t Loss: 1362.818170136225\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44455445544554456\n",
      "Epoch: 5600 \t Loss: 1360.9301241448288\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44356435643564357\n",
      "Epoch: 5700 \t Loss: 1359.0857762414987\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44455445544554456\n",
      "Epoch: 5800 \t Loss: 1357.283567701756\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44455445544554456\n",
      "Epoch: 5900 \t Loss: 1355.5220145479018\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44455445544554456\n",
      "Epoch: 6000 \t Loss: 1353.7997031694113\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44554455445544555\n",
      "Epoch: 6100 \t Loss: 1352.1152862374147\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44653465346534654\n",
      "Epoch: 6200 \t Loss: 1350.4674788916755\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.44752475247524753\n",
      "Epoch: 6300 \t Loss: 1348.8550551801482\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4485148514851485\n",
      "Epoch: 6400 \t Loss: 1347.276844732702\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4514851485148515\n",
      "Epoch: 6500 \t Loss: 1345.7317296520378\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4524752475247525\n",
      "Epoch: 6600 \t Loss: 1344.2186416061031\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4524752475247525\n",
      "Epoch: 6700 \t Loss: 1342.736559107534\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4504950495049505\n",
      "Epoch: 6800 \t Loss: 1341.2845049667565\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4514851485148515\n",
      "Epoch: 6900 \t Loss: 1339.861543906396\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4514851485148515\n",
      "Epoch: 7000 \t Loss: 1338.4667803256025\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4504950495049505\n",
      "Epoch: 7100 \t Loss: 1337.0993562037522\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4524752475247525\n",
      "Epoch: 7200 \t Loss: 1335.758449133793\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.45445544554455447\n",
      "Epoch: 7300 \t Loss: 1334.4432704762385\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.45544554455445546\n",
      "Epoch: 7400 \t Loss: 1333.1530636254922\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.45544554455445546\n",
      "Epoch: 7500 \t Loss: 1331.8871023808038\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.45544554455445546\n",
      "Epoch: 7600 \t Loss: 1330.6446894147414\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.45643564356435645\n",
      "Epoch: 7700 \t Loss: 1329.4251548325897\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4594059405940594\n",
      "Epoch: 7800 \t Loss: 1328.227854816566\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4603960396039604\n",
      "Epoch: 7900 \t Loss: 1327.0521703492068\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4613861386138614\n",
      "Epoch: 8000 \t Loss: 1325.8975060106825\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4613861386138614\n",
      "Epoch: 8100 \t Loss: 1324.7632888451813\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4613861386138614\n",
      "Epoch: 8200 \t Loss: 1323.6489672918556\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4633663366336634\n",
      "Epoch: 8300 \t Loss: 1322.5540101761533\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4623762376237624\n",
      "Epoch: 8400 \t Loss: 1321.4779057576402\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 8500 \t Loss: 1320.4201608307221\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 8600 \t Loss: 1319.3802998748984\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 8700 \t Loss: 1318.3578642514435\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 8800 \t Loss: 1317.35241144361\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 8900 \t Loss: 1316.3635143376553\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 9000 \t Loss: 1315.390760542186\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 9100 \t Loss: 1314.4337517434722\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 9200 \t Loss: 1313.492103094557\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 9300 \t Loss: 1312.5654426361211\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 9400 \t Loss: 1311.6534107472146\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 9500 \t Loss: 1310.7556596240752\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 9600 \t Loss: 1309.8718527853869\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47029702970297027\n",
      "Epoch: 9700 \t Loss: 1309.001664602433\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 9800 \t Loss: 1308.1447798526979\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 9900 \t Loss: 1307.3008932955677\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 10000 \t Loss: 1306.469709268872\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 10100 \t Loss: 1305.6509413050794\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 10200 \t Loss: 1304.844311766039\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 10300 \t Loss: 1304.0495514952404\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 10400 \t Loss: 1303.266399486609\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46534653465346537\n",
      "Epoch: 10500 \t Loss: 1302.4946025689328\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46534653465346537\n",
      "Epoch: 10600 \t Loss: 1301.7339151050642\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 10700 \t Loss: 1300.984098705093\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 10800 \t Loss: 1300.2449219527425\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 10900 \t Loss: 1299.5161601442737\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 11000 \t Loss: 1298.797595039242\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46534653465346537\n",
      "Epoch: 11100 \t Loss: 1298.0890146224717\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46534653465346537\n",
      "Epoch: 11200 \t Loss: 1297.3902128766706\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4633663366336634\n",
      "Epoch: 11300 \t Loss: 1296.7009895651236\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4633663366336634\n",
      "Epoch: 11400 \t Loss: 1296.0211500239493\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4633663366336634\n",
      "Epoch: 11500 \t Loss: 1295.3505049634289\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4623762376237624\n",
      "Epoch: 11600 \t Loss: 1294.6888702779438\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4623762376237624\n",
      "Epoch: 11700 \t Loss: 1294.0360668640888\n",
      "Pred: [4 0 0 ... 0 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4633663366336634\n",
      "Epoch: 11800 \t Loss: 1293.3919204465506\n",
      "Pred: [4 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4643564356435644\n",
      "Epoch: 11900 \t Loss: 1292.7562614113626\n",
      "Pred: [4 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46534653465346537\n",
      "Epoch: 12000 \t Loss: 1292.1289246461724\n",
      "Pred: [4 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4643564356435644\n",
      "Epoch: 12100 \t Loss: 1291.5097493871783\n",
      "Pred: [4 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4643564356435644\n",
      "Epoch: 12200 \t Loss: 1290.8985790724087\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46534653465346537\n",
      "Epoch: 12300 \t Loss: 1290.2952612010336\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 12400 \t Loss: 1289.699647198424\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 12500 \t Loss: 1289.111592286679\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46633663366336636\n",
      "Epoch: 12600 \t Loss: 1288.5309553603659\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 12700 \t Loss: 1287.9575988672202\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 12800 \t Loss: 1287.3913886935834\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 12900 \t Loss: 1286.8321940543462\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 13000 \t Loss: 1286.279887387202\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 13100 \t Loss: 1285.734344250999\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 13200 \t Loss: 1285.1954432280172\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46732673267326735\n",
      "Epoch: 13300 \t Loss: 1284.6630658299823\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4693069306930693\n",
      "Epoch: 13400 \t Loss: 1284.1370964076536\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 13500 \t Loss: 1283.6174220638263\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.46831683168316834\n",
      "Epoch: 13600 \t Loss: 1283.1039325695929\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47029702970297027\n",
      "Epoch: 13700 \t Loss: 1282.5965202837235\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47029702970297027\n",
      "Epoch: 13800 \t Loss: 1282.0950800750284\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47029702970297027\n",
      "Epoch: 13900 \t Loss: 1281.5995092475687\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47128712871287126\n",
      "Epoch: 14000 \t Loss: 1281.1097074685974\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47227722772277225\n",
      "Epoch: 14100 \t Loss: 1280.6255766991117\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47326732673267324\n",
      "Epoch: 14200 \t Loss: 1280.1470211269002\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47227722772277225\n",
      "Epoch: 14300 \t Loss: 1279.6739471019882\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47227722772277225\n",
      "Epoch: 14400 \t Loss: 1279.2062630743721\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47227722772277225\n",
      "Epoch: 14500 \t Loss: 1278.7438795339522\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47227722772277225\n",
      "Epoch: 14600 \t Loss: 1278.2867089525662\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47128712871287126\n",
      "Epoch: 14700 \t Loss: 1277.8346657280463\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47425742574257423\n",
      "Epoch: 14800 \t Loss: 1277.3876661302052\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47425742574257423\n",
      "Epoch: 14900 \t Loss: 1276.9456282486826\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.47425742574257423\n",
      "Epoch: 15000 \t Loss: 1276.5084719425688\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4752475247524752\n",
      "Epoch: 15100 \t Loss: 1276.0761187917374\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4752475247524752\n",
      "Epoch: 15200 \t Loss: 1275.6484920498199\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4762376237623762\n",
      "Epoch: 15300 \t Loss: 1275.2255165987535\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4762376237623762\n",
      "Epoch: 15400 \t Loss: 1274.8071189048403\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 15500 \t Loss: 1274.3932269762618\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 15600 \t Loss: 1273.9837703219873\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 15700 \t Loss: 1273.5786799120249\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 15800 \t Loss: 1273.177888138962\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 15900 \t Loss: 1272.7813287807462\n",
      "Pred: [0 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 16000 \t Loss: 1272.388936964659\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 16100 \t Loss: 1272.000649132438\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 16200 \t Loss: 1271.6164030065006\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 16300 \t Loss: 1271.2361375572352\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 16400 \t Loss: 1270.859792971311\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 16500 \t Loss: 1270.4873106209764\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 16600 \t Loss: 1270.1186330343044\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 16700 \t Loss: 1269.7537038663531\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 16800 \t Loss: 1269.3924678712076\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 16900 \t Loss: 1269.0348708748697\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 17000 \t Loss: 1268.6808597489667\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 17100 \t Loss: 1268.3303823852486\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 17200 \t Loss: 1267.9833876708494\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 17300 \t Loss: 1267.6398254642763\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 17400 \t Loss: 1267.2996465721142\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 17500 \t Loss: 1266.9628027264089\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 17600 \t Loss: 1266.6292465627107\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4762376237623762\n",
      "Epoch: 17700 \t Loss: 1266.298931598758\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 17800 \t Loss: 1265.9718122137695\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 17900 \t Loss: 1265.647843628338\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 18000 \t Loss: 1265.3269818848917\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 18100 \t Loss: 1265.0091838287117\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 18200 \t Loss: 1264.694407089487\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 18300 \t Loss: 1264.3826100633837\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 18400 \t Loss: 1264.0737518956169\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 18500 \t Loss: 1263.7677924635054\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 18600 \t Loss: 1263.4646923599962\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 18700 \t Loss: 1263.1644128776366\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 18800 \t Loss: 1262.8669159929905\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 18900 \t Loss: 1262.5721643514742\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 19000 \t Loss: 1262.280121252602\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 19100 \t Loss: 1261.99075063563\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 19200 \t Loss: 1261.704017065585\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 19300 \t Loss: 1261.419885719662\n",
      "Pred: [3 0 0 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 19400 \t Loss: 1261.138322373984\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 19500 \t Loss: 1260.8592933907107\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 19600 \t Loss: 1260.582765705484\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 19700 \t Loss: 1260.3087068152026\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 19800 \t Loss: 1260.037084766112\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 19900 \t Loss: 1259.767868142202\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 20000 \t Loss: 1259.5010260539048\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 20100 \t Loss: 1259.2365281270786\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 20200 \t Loss: 1258.9743444922751\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 20300 \t Loss: 1258.7144457742738\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 20400 \t Loss: 1258.4568030818855\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 20500 \t Loss: 1258.2013879980077\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 20600 \t Loss: 1257.9481725699295\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48316831683168315\n",
      "Epoch: 20700 \t Loss: 1257.6971292998765\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48316831683168315\n",
      "Epoch: 20800 \t Loss: 1257.4482311357895\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48316831683168315\n",
      "Epoch: 20900 \t Loss: 1257.201451462333\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 21000 \t Loss: 1256.9567640921173\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 21100 \t Loss: 1256.7141432571418\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 21200 \t Loss: 1256.4735636004398\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48316831683168315\n",
      "Epoch: 21300 \t Loss: 1256.2350001679306\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48316831683168315\n",
      "Epoch: 21400 \t Loss: 1255.9984284004609\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48316831683168315\n",
      "Epoch: 21500 \t Loss: 1255.7638241260438\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 21600 \t Loss: 1255.5311635522762\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 21700 \t Loss: 1255.3004232589412\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 21800 \t Loss: 1255.07158019078\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 21900 \t Loss: 1254.8446116504388\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 22000 \t Loss: 1254.6194952915766\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 22100 \t Loss: 1254.3962091121357\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 22200 \t Loss: 1254.174731447767\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 22300 \t Loss: 1253.9550409654084\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 22400 \t Loss: 1253.737116657011\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 22500 \t Loss: 1253.5209378334043\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 22600 \t Loss: 1253.306484118309\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 22700 \t Loss: 1253.093735442479\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 22800 \t Loss: 1252.8826720379789\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 22900 \t Loss: 1252.673274432589\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 23000 \t Loss: 1252.465523444338\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48316831683168315\n",
      "Epoch: 23100 \t Loss: 1252.2594001761531\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 23200 \t Loss: 1252.0548860106328\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 23300 \t Loss: 1251.851962604936\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 23400 \t Loss: 1251.650611885779\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 23500 \t Loss: 1251.4508160445466\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 23600 \t Loss: 1251.2525575325094\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 23700 \t Loss: 1251.0558190561424\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 23800 \t Loss: 1250.860583572549\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 23900 \t Loss: 1250.6668342849812\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 24000 \t Loss: 1250.4745546384556\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 24100 \t Loss: 1250.2837283154663\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 24200 \t Loss: 1250.0943392317872\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 24300 \t Loss: 1249.9063715323618\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 24400 \t Loss: 1249.7198095872845\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 24500 \t Loss: 1249.5346379878627\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 24600 \t Loss: 1249.3508415427623\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 24700 \t Loss: 1249.1684052742362\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4772277227722772\n",
      "Epoch: 24800 \t Loss: 1248.9873144144285\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 24900 \t Loss: 1248.807554401757\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 25000 \t Loss: 1248.62911087737\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 25100 \t Loss: 1248.4519696816765\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 25200 \t Loss: 1248.276116850947\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 25300 \t Loss: 1248.1015386139843\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 25400 \t Loss: 1247.9282213888625\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 25500 \t Loss: 1247.7561517797312\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 25600 \t Loss: 1247.5853165736848\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 25700 \t Loss: 1247.4157027376957\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 25800 \t Loss: 1247.2472974156071\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 25900 \t Loss: 1247.0800879251883\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 26000 \t Loss: 1246.914061755247\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 26100 \t Loss: 1246.7492065627998\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 26200 \t Loss: 1246.5855101702982\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 26300 \t Loss: 1246.42296056291\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 26400 \t Loss: 1246.2615458858527\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 26500 \t Loss: 1246.1012544417813\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 26600 \t Loss: 1245.942074688225\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 26700 \t Loss: 1245.7839952350746\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 26800 \t Loss: 1245.62700484212\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 26900 \t Loss: 1245.4710924166313\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27000 \t Loss: 1245.316247010991\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27100 \t Loss: 1245.1624578203696\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27200 \t Loss: 1245.0097141804447\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27300 \t Loss: 1244.8580055651644\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27400 \t Loss: 1244.7073215845544\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27500 \t Loss: 1244.557651982565\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27600 \t Loss: 1244.4089866349584\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27700 \t Loss: 1244.2613155472382\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27800 \t Loss: 1244.1146288526131\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 27900 \t Loss: 1243.9689168100053\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 28000 \t Loss: 1243.8241698020893\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 28100 \t Loss: 1243.6803783333708\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28200 \t Loss: 1243.5375330283005\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28300 \t Loss: 1243.3956246294222\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28400 \t Loss: 1243.2546439955559\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28500 \t Loss: 1243.114582100012\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28600 \t Loss: 1242.9754300288414\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28700 \t Loss: 1242.8371789791138\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28800 \t Loss: 1242.699820257231\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 28900 \t Loss: 1242.5633452772668\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29000 \t Loss: 1242.4277455593403\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29100 \t Loss: 1242.293012728016\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29200 \t Loss: 1242.1591385107342\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29300 \t Loss: 1242.026114736268\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29400 \t Loss: 1241.8939333332096\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29500 \t Loss: 1241.7625863284811\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29600 \t Loss: 1241.6320658458742\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 29700 \t Loss: 1241.502364104613\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 29800 \t Loss: 1241.373473417945\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 29900 \t Loss: 1241.2453861917547\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 30000 \t Loss: 1241.1180949232016\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 30100 \t Loss: 1240.9915921993834\n",
      "Pred: [3 0 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 30200 \t Loss: 1240.865870696021\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 30300 \t Loss: 1240.7409231761656\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 30400 \t Loss: 1240.6167424889318\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 30500 \t Loss: 1240.4933215682481\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 30600 \t Loss: 1240.3706534316314\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 30700 \t Loss: 1240.2487311789823\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 30800 \t Loss: 1240.1275479913993\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 30900 \t Loss: 1240.0070971300163\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 31000 \t Loss: 1239.8873719348571\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 31100 \t Loss: 1239.76836582371\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 31200 \t Loss: 1239.6500722910216\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 31300 \t Loss: 1239.532484906811\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 31400 \t Loss: 1239.415597315598\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 31500 \t Loss: 1239.299403235353\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 31600 \t Loss: 1239.1838964564645\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 31700 \t Loss: 1239.0690708407196\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 31800 \t Loss: 1238.9549203203073\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 31900 \t Loss: 1238.8414388968333\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 32000 \t Loss: 1238.7286206403542\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 32100 \t Loss: 1238.6164596884264\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4782178217821782\n",
      "Epoch: 32200 \t Loss: 1238.50495024517\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 32300 \t Loss: 1238.3940865803506\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 32400 \t Loss: 1238.2838630284728\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 32500 \t Loss: 1238.1742739878896\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 32600 \t Loss: 1238.0653139199285\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 32700 \t Loss: 1237.9569773480284\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 32800 \t Loss: 1237.8492588568934\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 32900 \t Loss: 1237.7421530916558\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 33000 \t Loss: 1237.635654757061\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4792079207920792\n",
      "Epoch: 33100 \t Loss: 1237.5297586166541\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33200 \t Loss: 1237.4244594919896\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33300 \t Loss: 1237.319752261848\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33400 \t Loss: 1237.2156318614664\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33500 \t Loss: 1237.1120932817823\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33600 \t Loss: 1237.0091315686882\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33700 \t Loss: 1236.9067418222965\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33800 \t Loss: 1236.8049191962205\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 33900 \t Loss: 1236.7036588968622\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.4801980198019802\n",
      "Epoch: 34000 \t Loss: 1236.602956182713\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 34100 \t Loss: 1236.502806363666\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 34200 \t Loss: 1236.4032048003376\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 34300 \t Loss: 1236.3041469034013\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 34400 \t Loss: 1236.2056281329303\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 34500 \t Loss: 1236.1076439977508\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 34600 \t Loss: 1236.0101900548052\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48118811881188117\n",
      "Epoch: 34700 \t Loss: 1235.9132619085267\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 34800 \t Loss: 1235.8168552102202\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Epoch: 34900 \t Loss: 1235.7209656574555\n",
      "Pred: [3 1 1 ... 1 0 0] \t truth: [4 3 2 ... 2 2 2]\n",
      "Accuracy:  0.48217821782178216\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the class\n",
    "model = MultiClass_LogisticReg(tf_idf_matrix.shape[1],len(np.unique(y_train)))\n",
    "\n",
    "#Train the Model\n",
    "model.fit(tf_idf_matrix,y_train)\n",
    "\n",
    "#Save the Trained Model Parameter\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and using saved model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Pred: [3 0 0 0 1 0 1 4 0 0 0 0 1 0 2 1 0 0 3 0 0 0 1 0 1 1 1 0 0 2 0 4 3 0 0 3 3\n",
      " 4 0 1 0 1 0 1 0 0 0 4 0 0 3 4 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 4 0 2 2\n",
      " 3 0 3 0 1 0 0 3 0 2 0 0 0 0 1 0 0 1 0 1 2 0 1 0 0 1 0 4 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 2 0 0 4 3 1 0 3 0 0 0 4 0 3 4 1 1 0 0 2 0 0 4 1 0 0 1 0 0 0 0 3 0 0\n",
      " 1 3 0 3 0 0 4 0 1 0 0 0 1 0 3 0 1 0 4 3 0 0 0 1 0 0 2 0 3 0 3 1 0 0 0 2 0\n",
      " 0 0 0 0 3 3 3 0 0 0 1 0 4 0 1 3 0 3 3 1 0 0 0 0 3 0 0 0 1 0 0 0 0 0 0 4 0\n",
      " 3 1 3 0 0 0 2 0 4 0 0 3 3 0 0 3 0 2 0 1 4 0 0 0 0 0 4 3 3 1 4] \t truth: [4 3 4 1 3 4 1 4 3 4 0 0 1 4 1 4 0 0 3 1 4 4 2 2 4 4 4 3 0 3 3 4 3 3 0 4 2\n",
      " 4 0 2 4 0 0 1 0 4 0 4 1 0 3 4 3 4 2 1 4 0 0 1 2 4 4 2 3 1 4 0 1 3 4 2 1 0\n",
      " 2 0 3 3 0 3 1 1 4 1 0 0 3 0 4 4 1 3 0 2 0 0 2 4 3 4 1 2 4 1 2 2 3 2 2 4 4\n",
      " 3 2 4 2 2 2 4 2 4 2 3 4 1 0 4 2 3 3 3 4 0 1 3 3 1 3 4 4 2 2 3 3 2 0 3 1 1\n",
      " 4 4 3 3 0 0 4 0 4 0 1 1 1 1 2 4 4 2 4 2 0 0 4 1 1 0 3 0 3 4 3 1 2 1 4 1 3\n",
      " 0 4 0 0 3 1 2 4 2 4 4 4 0 0 3 2 4 0 3 2 3 0 0 1 2 1 0 3 0 2 4 3 2 4 2 3 0\n",
      " 3 2 2 4 1 3 3 0 0 1 4 1 3 4 1 3 1 3 0 3 4 0 1 4 1 0 4 4 4 3 4]\n",
      "Test Accuracy:  0.31225296442687744\n"
     ]
    }
   ],
   "source": [
    "# Load Saved Model for prediction\n",
    "# Instantiate the class\n",
    "model = MultiClass_LogisticReg(tf_idf_matrix.shape[1],len(np.unique(y_train)))\n",
    "\n",
    "# Load the model parameters\n",
    "model.load_model('tf_idf_LR.npz')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_text_tf_idf_matrix)\n",
    "\n",
    "accuracy = model.get_accuracy(predictions, y_test) #Get Accuracy\n",
    "\n",
    "print(\"Test Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 1 4 4 4 4\n",
      " 4 4 2 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4\n",
      " 4 1 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 0 1 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4\n",
      " 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 3 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4] \t truth: [4 3 4 1 3 4 1 4 3 4 0 0 1 4 1 4 0 0 3 1 4 4 2 2 4 4 4 3 0 3 3 4 3 3 0 4 2\n",
      " 4 0 2 4 0 0 1 0 4 0 4 1 0 3 4 3 4 2 1 4 0 0 1 2 4 4 2 3 1 4 0 1 3 4 2 1 0\n",
      " 2 0 3 3 0 3 1 1 4 1 0 0 3 0 4 4 1 3 0 2 0 0 2 4 3 4 1 2 4 1 2 2 3 2 2 4 4\n",
      " 3 2 4 2 2 2 4 2 4 2 3 4 1 0 4 2 3 3 3 4 0 1 3 3 1 3 4 4 2 2 3 3 2 0 3 1 1\n",
      " 4 4 3 3 0 0 4 0 4 0 1 1 1 1 2 4 4 2 4 2 0 0 4 1 1 0 3 0 3 4 3 1 2 1 4 1 3\n",
      " 0 4 0 0 3 1 2 4 2 4 4 4 0 0 3 2 4 0 3 2 3 0 0 1 2 1 0 3 0 2 4 3 2 4 2 3 0\n",
      " 3 2 2 4 1 3 3 0 0 1 4 1 3 4 1 3 1 3 0 3 4 0 1 4 1 0 4 4 4 3 4]\n",
      "Test Accuracy:  0.2964426877470356\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test is your true labels for the test set\n",
    "predicted_labels = model.predict(xtest_features) #Call the Predict class\n",
    "accuracy = model.get_accuracy(predicted_labels, y_test) #Get Accuracy\n",
    "\n",
    "print(\"Test Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Sckit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maryk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maryk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5296442687747036\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.62      0.53        56\n",
      "           1       0.58      0.36      0.44        50\n",
      "           2       0.56      0.41      0.47        49\n",
      "           3       0.47      0.60      0.53        42\n",
      "           4       0.63      0.64      0.64        56\n",
      "\n",
      "    accuracy                           0.53       253\n",
      "   macro avg       0.54      0.53      0.52       253\n",
      "weighted avg       0.54      0.53      0.52       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming your dataset has columns 'text' and 'humour_style'\n",
    "# Adjust the path and format accordingly\n",
    "dataset_path = 'Humour_style.xlsx'\n",
    "df = pd.read_excel(dataset_path)\n",
    "\n",
    "# Preprocess the text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [ps.stem(word.lower()) for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['processed_text'] = df['JOKES'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['processed_text'], df['LABELS'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Train a multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', max_iter=500)\n",
    "model.fit(X_train_tfidf, y_train_encoded)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "classification_rep = classification_report(y_test_encoded, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "torch.Size([1010, 5])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics import BinaryConfusionMatrix, BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "\n",
    "# Creates a Tensor from a numpy.ndarray.\n",
    "# Any changes you make to the tensor will reflect in the original NumPy array\n",
    "x_train_tensor = torch.from_numpy(xtrain_features).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).int()\n",
    "x_test_tensor = torch.from_numpy(xtest_features).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()\n",
    "\n",
    "## Changing labels to one-hot encoding to match output size\n",
    "y_train_tensor = y_train_tensor.long() # If y_train_tensor is of type float, convert it to integer first\n",
    "num_classes = len(torch.unique(y_train_tensor)) # Determine the number of classes\n",
    "y_train_tensor = F.one_hot(y_train_tensor, num_classes=num_classes) # Convert to one-hot encoding\n",
    "y_train_tensor = y_train_tensor.float() #Convert long type back to float as BCELOSS uses float\n",
    "\n",
    "# Ask PyTorch to store any computed gradients so that we can examine them\n",
    "x_train_tensor.requires_grad_(True)\n",
    "\n",
    "# should be \"None\" at the moment. It will only be filled later after you call backward()\n",
    "print(x_train_tensor.grad)\n",
    "\n",
    "# Use a GPU if it exists\n",
    "if torch.cuda.is_available():\n",
    "    x_train_tensor = x_train_tensor.to('cuda')\n",
    "    x_test_tensor = x_test_tensor.to('cuda')\n",
    "    y_train_tensor = y_train_tensor.to('cuda')\n",
    "\n",
    "print(y_train_tensor.shape)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 6.5029e-03,  7.2377e-04,  5.0142e-04,  ..., -9.0817e-03,\n",
      "         -8.5354e-03, -7.1694e-03],\n",
      "        [-3.2552e-03, -5.7002e-03, -3.0747e-04,  ...,  5.3260e-03,\n",
      "          7.8789e-03, -2.0703e-03],\n",
      "        [-1.7740e-03, -7.2498e-03, -3.8780e-03,  ..., -6.0786e-03,\n",
      "         -3.0342e-03, -4.4540e-03],\n",
      "        [ 8.7529e-03,  8.3549e-03, -1.6993e-03,  ...,  1.6336e-03,\n",
      "          6.5671e-03,  5.7072e-03],\n",
      "        [ 6.0905e-03,  1.5982e-03,  5.7385e-03,  ...,  5.9996e-05,\n",
      "          3.6836e-04, -6.3659e-03]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0071,  0.0043, -0.0091, -0.0082, -0.0012], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "[Parameter containing:\n",
      "tensor([[ 6.5029e-03,  7.2377e-04,  5.0142e-04,  ..., -9.0817e-03,\n",
      "         -8.5354e-03, -7.1694e-03],\n",
      "        [-3.2552e-03, -5.7002e-03, -3.0747e-04,  ...,  5.3260e-03,\n",
      "          7.8789e-03, -2.0703e-03],\n",
      "        [-1.7740e-03, -7.2498e-03, -3.8780e-03,  ..., -6.0786e-03,\n",
      "         -3.0342e-03, -4.4540e-03],\n",
      "        [ 8.7529e-03,  8.3549e-03, -1.6993e-03,  ...,  1.6336e-03,\n",
      "          6.5671e-03,  5.7072e-03],\n",
      "        [ 6.0905e-03,  1.5982e-03,  5.7385e-03,  ...,  5.9996e-05,\n",
      "          3.6836e-04, -6.3659e-03]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0071,  0.0043, -0.0091, -0.0082, -0.0012], device='cuda:0',\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax() ##Sigmoid activation function\n",
    "\n",
    "class LogisticRegressionPytorch(nn.Module):\n",
    "    def __init__(self, n_input_vars, n_output_vars=5):\n",
    "        super().__init__() # call constructor of superclass\n",
    "        # CLASS torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "        self.linear = nn.Linear(n_input_vars, n_output_vars)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return m(self.linear(x))\n",
    "    \n",
    "\n",
    "input_n = xtrain_features.shape[1]\n",
    "py_model = LogisticRegressionPytorch(input_n)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    py_model.to('cuda')\n",
    "\n",
    "print(py_model.linear.weight) # Print Weights\n",
    "print(py_model.linear.bias)   # Print Bias\n",
    "print(list(py_model.parameters())) # Print LR parameters (Both weight and Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maryk\\AppData\\Local\\Temp\\ipykernel_4120\\2437056227.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return m(self.linear(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1010, 5])\n",
      "Epoch: 0\t L: 0.9050\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 2\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 3\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 4\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 5\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 6\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 7\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 8\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 9\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 10\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 11\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 12\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 13\t L: 0.9049\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 14\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 15\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 16\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 17\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 18\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 19\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 20\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 21\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 22\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 23\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 24\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 25\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 26\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 27\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 28\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 29\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 30\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 31\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 32\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 33\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 34\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 35\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 36\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 37\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 38\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 39\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 40\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 41\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 42\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 43\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 44\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 45\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 46\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 47\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 48\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 49\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 50\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 51\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 52\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 53\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 54\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 55\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 56\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 57\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 58\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 59\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 60\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 61\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 62\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 63\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 64\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 65\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 66\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 67\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 68\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 69\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 70\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 71\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 72\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 73\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 74\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 75\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 76\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 77\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 78\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 79\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 80\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 81\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 82\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 83\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 84\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 85\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 86\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 87\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 88\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 89\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 90\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 91\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 92\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 93\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 94\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 95\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 96\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 97\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 98\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 99\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 100\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 101\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 102\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 103\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 104\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 105\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 106\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 107\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 108\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 109\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 110\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 111\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 112\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 113\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 114\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 115\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 116\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 117\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 118\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 119\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 120\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 121\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 122\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 123\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 124\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 125\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 126\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 127\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 128\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 129\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 130\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 131\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 132\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 133\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 134\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 135\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 136\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 137\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 138\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 139\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 140\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 141\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 142\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 143\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 144\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 145\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 146\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 147\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 148\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 149\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 150\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 151\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 152\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 153\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 154\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 155\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 156\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 157\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 158\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 159\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 160\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 161\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 162\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 163\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 164\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 165\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 166\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 167\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 168\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 169\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 170\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 171\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 172\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 173\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 174\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 175\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 176\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 177\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 178\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 179\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 180\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 181\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 182\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 183\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 184\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 185\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 186\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 187\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 188\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 189\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 190\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 191\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 192\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 193\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 194\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 195\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 196\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 197\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 198\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 199\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 200\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 201\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 202\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 203\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 204\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 205\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 206\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 207\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 208\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 209\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 210\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 211\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 212\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 213\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 214\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 215\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 216\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 217\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 218\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 219\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 220\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 221\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 222\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 223\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 224\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 225\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 226\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 227\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 228\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 229\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 230\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 231\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 232\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 233\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 234\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 235\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 236\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 237\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 238\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 239\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 240\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 241\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 242\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 243\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 244\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 245\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 246\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 247\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 248\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 249\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 250\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 251\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 252\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 253\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 254\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 255\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 256\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 257\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 258\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 259\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 260\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 261\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 262\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 263\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 264\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 265\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 266\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 267\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 268\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 269\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 270\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 271\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 272\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 273\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 274\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 275\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 276\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 277\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 278\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 279\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 280\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 281\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 282\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 283\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 284\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 285\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 286\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 287\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 288\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 289\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 290\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 291\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 292\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 293\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 294\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 295\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 296\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 297\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 298\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 299\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 300\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 301\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 302\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 303\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 304\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 305\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 306\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 307\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 308\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 309\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 310\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 311\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 312\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 313\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 314\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 315\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 316\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 317\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 318\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 319\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 320\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 321\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 322\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 323\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 324\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 325\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 326\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 327\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 328\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 329\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 330\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 331\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 332\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 333\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 334\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 335\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 336\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 337\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 338\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 339\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 340\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 341\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 342\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 343\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 344\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 345\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 346\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 347\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 348\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 349\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 350\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 351\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 352\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 353\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 354\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 355\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 356\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 357\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 358\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 359\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 360\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 361\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 362\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 363\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 364\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 365\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 366\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 367\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 368\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 369\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 370\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 371\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 372\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 373\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 374\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 375\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 376\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 377\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 378\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 379\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 380\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 381\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 382\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 383\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 384\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 385\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 386\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 387\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 388\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 389\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 390\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 391\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 392\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 393\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 394\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 395\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 396\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 397\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 398\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 399\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 400\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 401\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 402\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 403\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 404\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 405\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 406\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 407\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 408\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 409\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 410\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 411\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 412\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 413\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 414\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 415\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 416\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 417\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 418\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 419\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 420\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 421\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 422\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 423\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 424\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 425\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 426\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 427\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 428\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 429\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 430\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 431\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 432\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 433\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 434\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 435\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 436\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 437\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 438\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 439\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 440\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 441\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 442\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 443\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 444\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 445\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 446\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 447\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 448\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 449\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 450\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 451\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 452\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 453\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 454\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 455\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 456\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 457\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 458\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 459\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 460\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 461\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 462\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 463\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 464\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 465\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 466\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 467\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 468\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 469\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 470\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 471\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 472\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 473\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 474\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 475\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 476\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 477\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 478\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 479\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 480\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 481\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 482\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 483\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 484\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 485\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 486\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 487\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 488\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 489\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 490\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 491\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 492\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 493\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 494\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 495\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 496\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 497\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 498\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 499\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 500\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 501\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 502\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 503\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 504\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 505\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 506\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 507\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 508\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 509\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 510\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 511\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 512\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 513\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 514\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 515\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 516\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 517\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 518\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 519\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 520\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 521\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 522\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 523\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 524\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 525\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 526\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 527\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 528\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 529\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 530\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 531\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 532\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 533\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 534\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 535\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 536\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 537\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 538\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 539\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 540\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 541\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 542\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 543\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 544\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 545\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 546\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 547\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 548\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 549\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 550\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 551\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 552\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 553\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 554\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 555\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 556\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 557\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 558\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 559\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 560\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 561\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 562\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 563\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 564\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 565\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 566\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 567\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 568\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 569\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 570\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 571\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 572\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 573\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 574\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 575\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 576\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 577\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 578\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 579\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 580\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 581\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 582\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 583\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 584\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 585\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 586\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 587\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 588\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 589\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 590\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 591\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 592\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 593\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 594\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 595\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 596\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 597\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 598\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 599\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 600\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 601\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 602\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 603\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 604\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 605\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 606\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 607\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 608\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 609\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 610\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 611\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 612\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 613\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 614\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 615\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 616\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 617\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 618\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 619\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 620\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 621\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 622\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 623\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 624\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 625\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 626\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 627\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 628\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 629\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 630\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 631\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 632\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 633\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 634\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 635\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 636\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 637\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 638\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 639\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 640\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 641\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 642\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 643\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 644\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 645\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 646\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 647\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 648\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 649\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 650\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 651\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 652\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 653\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 654\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 655\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 656\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 657\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 658\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 659\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 660\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 661\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 662\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 663\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 664\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 665\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 666\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 667\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 668\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 669\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 670\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 671\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 672\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 673\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 674\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 675\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 676\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 677\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 678\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 679\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 680\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 681\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 682\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 683\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 684\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 685\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 686\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 687\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 688\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 689\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 690\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 691\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 692\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 693\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 694\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 695\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 696\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 697\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 698\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 699\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 700\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 701\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 702\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 703\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 704\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 705\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 706\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 707\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 708\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 709\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 710\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 711\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 712\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 713\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 714\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 715\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 716\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 717\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 718\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 719\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 720\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 721\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 722\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 723\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 724\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 725\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 726\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 727\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 728\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 729\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 730\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 731\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 732\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 733\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 734\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 735\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 736\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 737\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 738\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 739\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 740\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 741\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 742\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 743\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 744\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 745\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 746\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 747\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 748\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 749\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 750\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 751\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 752\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 753\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 754\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 755\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 756\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 757\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 758\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 759\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 760\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 761\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 762\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 763\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 764\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 765\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 766\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 767\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 768\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 769\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 770\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 771\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 772\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 773\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 774\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 775\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 776\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 777\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 778\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 779\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 780\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 781\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 782\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 783\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 784\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 785\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 786\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 787\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 788\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 789\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 790\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 791\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 792\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 793\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 794\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 795\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 796\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 797\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 798\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 799\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 800\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 801\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 802\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 803\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 804\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 805\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 806\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 807\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 808\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 809\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 810\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 811\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 812\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 813\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 814\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 815\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 816\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 817\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 818\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 819\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 820\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 821\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 822\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 823\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 824\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 825\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 826\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 827\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 828\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 829\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 830\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 831\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 832\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 833\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 834\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 835\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 836\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 837\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 838\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 839\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 840\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 841\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 842\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 843\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 844\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 845\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 846\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 847\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 848\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 849\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 850\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 851\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 852\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 853\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 854\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 855\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 856\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 857\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 858\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 859\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 860\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 861\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 862\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 863\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 864\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 865\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 866\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 867\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 868\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 869\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 870\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 871\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 872\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 873\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 874\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 875\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 876\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 877\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 878\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 879\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 880\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 881\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 882\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 883\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 884\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 885\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 886\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 887\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 888\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 889\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 890\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 891\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 892\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 893\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 894\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 895\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 896\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 897\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 898\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 899\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 900\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 901\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 902\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 903\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 904\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 905\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 906\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 907\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 908\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 909\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 910\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 911\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 912\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 913\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 914\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 915\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 916\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 917\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 918\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 919\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 920\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 921\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 922\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 923\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 924\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 925\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 926\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 927\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 928\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 929\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 930\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 931\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 932\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 933\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 934\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 935\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 936\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 937\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 938\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 939\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 940\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 941\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 942\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 943\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 944\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 945\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 946\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 947\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 948\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 949\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 950\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 951\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 952\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 953\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 954\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 955\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 956\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 957\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 958\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 959\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 960\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 961\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 962\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 963\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 964\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 965\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 966\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 967\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 968\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 969\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 970\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 971\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 972\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 973\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 974\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 975\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 976\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 977\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 978\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 979\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 980\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 981\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 982\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 983\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 984\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 985\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 986\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 987\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 988\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 989\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 990\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 991\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 992\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 993\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 994\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 995\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 996\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 997\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 998\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 999\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1000\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1001\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1002\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1003\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1004\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1005\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1006\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1007\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1008\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1009\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1010\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1011\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1012\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1013\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1014\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1015\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1016\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1017\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1018\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1019\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1020\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1021\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1022\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1023\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1024\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1025\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1026\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1027\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1028\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1029\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1030\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1031\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1032\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1033\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1034\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1035\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1036\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1037\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1038\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1039\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1040\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1041\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1042\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1043\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1044\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1045\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1046\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1047\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1048\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1049\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1050\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1051\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1052\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1053\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1054\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1055\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1056\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1057\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1058\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1059\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1060\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1061\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1062\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1063\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1064\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1065\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1066\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1067\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1068\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1069\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1070\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1071\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1072\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1073\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1074\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1075\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1076\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1077\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1078\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1079\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1080\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1081\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1082\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1083\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1084\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1085\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1086\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1087\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1088\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1089\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1090\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1091\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1092\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1093\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1094\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1095\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1096\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1097\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1098\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1099\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1100\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1101\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1102\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1103\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1104\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1105\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1106\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1107\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1108\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1109\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1110\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1111\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1112\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1113\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1114\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1115\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1116\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1117\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1118\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1119\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1120\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1121\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1122\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1123\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1124\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1125\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1126\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1127\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1128\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1129\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1130\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1131\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1132\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1133\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1134\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1135\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1136\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1137\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1138\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1139\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1140\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1141\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1142\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1143\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1144\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1145\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1146\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1147\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1148\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1149\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1150\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1151\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1152\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1153\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1154\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1155\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1156\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1157\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1158\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1159\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1160\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1161\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1162\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1163\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1164\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1165\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1166\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1167\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1168\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1169\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1170\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1171\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1172\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1173\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1174\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1175\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1176\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1177\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1178\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1179\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1180\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1181\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1182\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1183\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1184\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1185\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1186\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1187\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1188\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1189\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1190\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1191\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1192\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1193\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1194\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1195\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1196\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1197\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1198\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1199\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1200\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1201\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1202\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1203\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1204\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1205\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1206\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1207\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1208\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1209\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1210\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1211\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1212\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1213\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1214\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1215\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1216\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1217\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1218\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1219\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1220\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1221\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1222\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1223\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1224\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1225\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1226\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1227\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1228\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1229\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1230\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1231\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1232\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1233\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1234\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1235\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1236\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1237\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1238\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1239\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1240\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1241\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1242\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1243\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1244\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1245\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1246\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1247\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1248\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1249\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1250\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1251\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1252\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1253\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1254\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1255\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1256\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1257\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1258\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1259\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1260\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1261\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1262\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1263\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1264\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1265\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1266\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1267\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1268\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1269\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1270\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1271\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1272\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1273\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1274\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1275\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1276\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1277\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1278\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1279\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1280\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1281\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1282\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1283\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1284\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1285\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1286\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1287\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1288\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1289\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1290\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1291\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1292\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1293\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1294\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1295\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1296\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1297\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1298\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1299\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1300\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1301\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1302\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1303\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1304\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1305\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1306\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1307\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1308\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1309\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1310\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1311\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1312\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1313\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1314\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1315\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1316\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1317\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1318\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1319\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1320\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1321\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1322\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1323\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1324\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1325\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1326\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1327\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1328\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1329\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1330\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1331\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1332\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1333\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1334\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1335\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1336\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1337\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1338\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1339\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1340\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1341\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1342\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1343\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1344\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1345\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1346\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1347\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1348\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1349\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1350\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1351\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1352\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1353\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1354\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1355\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1356\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1357\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1358\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1359\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1360\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1361\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1362\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1363\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1364\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1365\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1366\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1367\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1368\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1369\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1370\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1371\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1372\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1373\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1374\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1375\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1376\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1377\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1378\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1379\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1380\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1381\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1382\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1383\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1384\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1385\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1386\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1387\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1388\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1389\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1390\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1391\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1392\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1393\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1394\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1395\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1396\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1397\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1398\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1399\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1400\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1401\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1402\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1403\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1404\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1405\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1406\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1407\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1408\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1409\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1410\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1411\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1412\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1413\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1414\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1415\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1416\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1417\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1418\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1419\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1420\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1421\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1422\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1423\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1424\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1425\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1426\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1427\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1428\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1429\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1430\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1431\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1432\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1433\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1434\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1435\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1436\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1437\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1438\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1439\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1440\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1441\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1442\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1443\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1444\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1445\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1446\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1447\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1448\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1449\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1450\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1451\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1452\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1453\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1454\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1455\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1456\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1457\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1458\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1459\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1460\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1461\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1462\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1463\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1464\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1465\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1466\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1467\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1468\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1469\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1470\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1471\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1472\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1473\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1474\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1475\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1476\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1477\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1478\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1479\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1480\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1481\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1482\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1483\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1484\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1485\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1486\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1487\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1488\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1489\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1490\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1491\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1492\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1493\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1494\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1495\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1496\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1497\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1498\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1499\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1500\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1501\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1502\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1503\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1504\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1505\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1506\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1507\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1508\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1509\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1510\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1511\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1512\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1513\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1514\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1515\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1516\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1517\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1518\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1519\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1520\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1521\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1522\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1523\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1524\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1525\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1526\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1527\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1528\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1529\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1530\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1531\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1532\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1533\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1534\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1535\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1536\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1537\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1538\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1539\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1540\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1541\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1542\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1543\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1544\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1545\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1546\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1547\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1548\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1549\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1550\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1551\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1552\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1553\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1554\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1555\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1556\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1557\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1558\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1559\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1560\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1561\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1562\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1563\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1564\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1565\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1566\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1567\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1568\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1569\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1570\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1571\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1572\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1573\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1574\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1575\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1576\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1577\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1578\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1579\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1580\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1581\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1582\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1583\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1584\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1585\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1586\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1587\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1588\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1589\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1590\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1591\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1592\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1593\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1594\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1595\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1596\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1597\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1598\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1599\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1600\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1601\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1602\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1603\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1604\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1605\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1606\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1607\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1608\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1609\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1610\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1611\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1612\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1613\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1614\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1615\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1616\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1617\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1618\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1619\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1620\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1621\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1622\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1623\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1624\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1625\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1626\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1627\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1628\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1629\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1630\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1631\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1632\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1633\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1634\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1635\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1636\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1637\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1638\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1639\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1640\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1641\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1642\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1643\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1644\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1645\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1646\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1647\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1648\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1649\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1650\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1651\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1652\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1653\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1654\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1655\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1656\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1657\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1658\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1659\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1660\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1661\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1662\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1663\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1664\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1665\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1666\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1667\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1668\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1669\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1670\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1671\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1672\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1673\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1674\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1675\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1676\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1677\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1678\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1679\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1680\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1681\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1682\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1683\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1684\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1685\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1686\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1687\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1688\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1689\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1690\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1691\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1692\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1693\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1694\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1695\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1696\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1697\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1698\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1699\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1700\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1701\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1702\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1703\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1704\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1705\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1706\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1707\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1708\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1709\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1710\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1711\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1712\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1713\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1714\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1715\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1716\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1717\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1718\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1719\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1720\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1721\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1722\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1723\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1724\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1725\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1726\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1727\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1728\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1729\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1730\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1731\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1732\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1733\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1734\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1735\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1736\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1737\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1738\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1739\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1740\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1741\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1742\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1743\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1744\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1745\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1746\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1747\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1748\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1749\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1750\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1751\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1752\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1753\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1754\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1755\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1756\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1757\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1758\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1759\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1760\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1761\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1762\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1763\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1764\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1765\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1766\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1767\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1768\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1769\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1770\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1771\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1772\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1773\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1774\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1775\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1776\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1777\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1778\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1779\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1780\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1781\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1782\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1783\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1784\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1785\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1786\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1787\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1788\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1789\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1790\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1791\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1792\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1793\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1794\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1795\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1796\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1797\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1798\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1799\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1800\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1801\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1802\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1803\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1804\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1805\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1806\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1807\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1808\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1809\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1810\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1811\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1812\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1813\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1814\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1815\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1816\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1817\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1818\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1819\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1820\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1821\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1822\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1823\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1824\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1825\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1826\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1827\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1828\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1829\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1830\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1831\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1832\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1833\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1834\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1835\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1836\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1837\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1838\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1839\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1840\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1841\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1842\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1843\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1844\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1845\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1846\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1847\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1848\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1849\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1850\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1851\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1852\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1853\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1854\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1855\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1856\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1857\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1858\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1859\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1860\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1861\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1862\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1863\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1864\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1865\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1866\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1867\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1868\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1869\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1870\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1871\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1872\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1873\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1874\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1875\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1876\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1877\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1878\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1879\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1880\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1881\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1882\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1883\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1884\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1885\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1886\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1887\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1888\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1889\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1890\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1891\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1892\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1893\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1894\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1895\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1896\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1897\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1898\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1899\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1900\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1901\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1902\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1903\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1904\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1905\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1906\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1907\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1908\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1909\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1910\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1911\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1912\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1913\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1914\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1915\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1916\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1917\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1918\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1919\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1920\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1921\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1922\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1923\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1924\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1925\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1926\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1927\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1928\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1929\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1930\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1931\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1932\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1933\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1934\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1935\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1936\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1937\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1938\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1939\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1940\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1941\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1942\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1943\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1944\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1945\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1946\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1947\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1948\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1949\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1950\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1951\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1952\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1953\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1954\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1955\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1956\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1957\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1958\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1959\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1960\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1961\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1962\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1963\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1964\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1965\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1966\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1967\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1968\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1969\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1970\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1971\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1972\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1973\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1974\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1975\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1976\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1977\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1978\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1979\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1980\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1981\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1982\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1983\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1984\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1985\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1986\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1987\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1988\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1989\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1990\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1991\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1992\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1993\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1994\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1995\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1996\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1997\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1998\t L: 0.9048\n",
      "torch.Size([1010, 5])\n",
      "Epoch: 1999\t L: 0.9048\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Binary cross entropy \n",
    "\n",
    "optimiser = torch.optim.Adam(py_model.parameters(), lr=0.01)\n",
    "\n",
    "n_epoch = 1000\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    # Reset the gradients\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    y_hat = py_model(x_train_tensor)\n",
    "    print(y_hat.shape)\n",
    "\n",
    "    # compute loss\n",
    "    loss = criterion(y_hat, y_train_tensor)\n",
    "\n",
    "    # Backward pass (compute the gradients)\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters (weight and bias)\n",
    "    optimiser.step()\n",
    "\n",
    "    # print(f\"Epoch: {epoch}\\t w: {model.linear.weight.data[0]}\\t b: {model.linear.bias.data[0]:.4f} \\t L: {loss:.4f}\")\n",
    "    print(f\"Epoch: {epoch}\\t L: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maryk\\AppData\\Local\\Temp\\ipykernel_4120\\2437056227.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return m(self.linear(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4., 3., 4., 1., 3., 4., 1., 4., 3., 4., 0., 0., 1., 4., 1., 4., 0., 0.,\n",
       "        3., 1., 4., 4., 2., 2., 4., 4., 4., 3., 0., 3., 3., 4., 3., 3., 0., 4.,\n",
       "        2., 4., 0., 2., 4., 0., 0., 1., 0., 4., 0., 4., 1., 0., 3., 4., 3., 4.,\n",
       "        2., 1., 4., 0., 0., 1., 2., 4., 4., 2., 3., 1., 4., 0., 1., 3., 4., 2.,\n",
       "        1., 0., 2., 0., 3., 3., 0., 3., 1., 1., 4., 1., 0., 0., 3., 0., 4., 4.,\n",
       "        1., 3., 0., 2., 0., 0., 2., 4., 3., 4., 1., 2., 4., 1., 2., 2., 3., 2.,\n",
       "        2., 4., 4., 3., 2., 4., 2., 2., 2., 4., 2., 4., 2., 3., 4., 1., 0., 4.,\n",
       "        2., 3., 3., 3., 4., 0., 1., 3., 3., 1., 3., 4., 4., 2., 2., 3., 3., 2.,\n",
       "        0., 3., 1., 1., 4., 4., 3., 3., 0., 0., 4., 0., 4., 0., 1., 1., 1., 1.,\n",
       "        2., 4., 4., 2., 4., 2., 0., 0., 4., 1., 1., 0., 3., 0., 3., 4., 3., 1.,\n",
       "        2., 1., 4., 1., 3., 0., 4., 0., 0., 3., 1., 2., 4., 2., 4., 4., 4., 0.,\n",
       "        0., 3., 2., 4., 0., 3., 2., 3., 0., 0., 1., 2., 1., 0., 3., 0., 2., 4.,\n",
       "        3., 2., 4., 2., 3., 0., 3., 2., 2., 4., 1., 3., 3., 0., 0., 1., 4., 1.,\n",
       "        3., 4., 1., 3., 1., 3., 0., 3., 4., 0., 1., 4., 1., 0., 4., 4., 4., 3.,\n",
       "        4.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = py_model.forward(x_test_tensor) # prediction is in one-hot encoded form\n",
    "binary_y_predictions= torch.argmax(y_predictions, dim=1) #convert it back to a one-dimensional tensor with binary values (0 or 1).\n",
    "binary_y_predictions = binary_y_predictions.to(torch.int64)\n",
    "\n",
    "\n",
    "y_predictions\n",
    "binary_y_predictions\n",
    "y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6522\n",
      "Precision: 0.6363\n",
      "Recall: 0.6522\n",
      "F1 Score: 0.6368\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.82      0.73        51\n",
      "         1.0       0.59      0.40      0.48        42\n",
      "         2.0       0.46      0.33      0.38        40\n",
      "         3.0       0.59      0.63      0.61        52\n",
      "         4.0       0.79      0.88      0.83        68\n",
      "\n",
      "    accuracy                           0.65       253\n",
      "   macro avg       0.62      0.61      0.61       253\n",
      "weighted avg       0.64      0.65      0.64       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Assuming y_predictions contains the predicted class indices\n",
    "# and y_test_tensor contains the true class indices\n",
    "\n",
    "# Sample data (replace these with your actual predictions and true labels)\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays\n",
    "multi_y_predictions = y_predictions.detach().cpu().numpy()\n",
    "multi_y_true = y_test_tensor.detach().cpu().numpy()\n",
    "\n",
    "# Convert predicted probabilities to class indices\n",
    "predicted_labels = np.argmax(multi_y_predictions, axis=1)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(multi_y_true, predicted_labels)\n",
    "precision = precision_score(multi_y_true, predicted_labels, average='weighted')\n",
    "recall = recall_score(multi_y_true, predicted_labels, average='weighted')\n",
    "f1 = f1_score(multi_y_true, predicted_labels, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(multi_y_true, predicted_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
